because we have perhaps stumbled in the
because we have perhaps stumbled in the
past that's no reason to think we need
past that's no reason to think we need
past that's no reason to think we need
to stumble in the future hold on to your
to stumble in the future hold on to your
to stumble in the future hold on to your
Technical and moral imaginations and we
Technical and moral imaginations and we
Technical and moral imaginations and we
will make progress you made me you know
will make progress you made me you know
will make progress you made me you know
king of the world we limit AIS to being
king of the world we limit AIS to being
king of the world we limit AIS to being
tools only tools to help humans solve
tools only tools to help humans solve
tools only tools to help humans solve
human problems and we do not give them
human problems and we do not give them
human problems and we do not give them
agency we do not allow them to take over
agency we do not allow them to take over
agency we do not allow them to take over
you know large systems we need
you know large systems we need
you know large systems we need
technology to keep them limited and
technology to keep them limited and
technology to keep them limited and
that's what I'm thinking a lot about
that's what I'm thinking a lot about
that's what I'm thinking a lot about
right now autonomous systems AI man with
right now autonomous systems AI man with
right now autonomous systems AI man with
ey patch we think you're training for
ey patch we think you're training for
ey patch we think you're training for
the next Bond villain that's very
the next Bond villain that's very
the next Bond villain that's very
appropriate for the topic we're going to
appropriate for the topic we're going to
appropriate for the topic we're going to
[Music]
discuss this is Star Talk special
discuss this is Star Talk special
edition Neil degrass Tyson you're a
edition Neil degrass Tyson you're a
edition Neil degrass Tyson you're a
personal astrophysicist and when we say
personal astrophysicist and when we say
personal astrophysicist and when we say
special edition it means I've got as
special edition it means I've got as
special edition it means I've got as
co-host Gary O'Reilly Gary hi Neil all
co-host Gary O'Reilly Gary hi Neil all
co-host Gary O'Reilly Gary hi Neil all
right Chuck nice baby hey hey what's up
right Chuck nice baby hey hey what's up
right Chuck nice baby hey hey what's up
Ma so I understand today because our
Ma so I understand today because our
Ma so I understand today because our
special edition themes are always people
special edition themes are always people
special edition themes are always people
our physiology our Behavior our conduct
our physiology our Behavior our conduct
our physiology our Behavior our conduct
our interaction with the world and
our interaction with the world and
our interaction with the world and
finally we're talking about Technologies
finally we're talking about Technologies
finally we're talking about Technologies
being safe and ethical yeah these are
being safe and ethical yeah these are
being safe and ethical yeah these are
three words you don't often see in a
three words you don't often see in a
three words you don't often see in a
sentence safe ethical technology and
sentence safe ethical technology and
sentence safe ethical technology and
this is where we're going to shine our
this is where we're going to shine our
this is where we're going to shine our
light where you going to take us today
light where you going to take us today
light where you going to take us today
it seems we have problems starting with
it seems we have problems starting with
it seems we have problems starting with
the letter A algorithms AI autonomous
the letter A algorithms AI autonomous
the letter A algorithms AI autonomous
well there's three for you is there a
well there's three for you is there a
well there's three for you is there a
wild West Tech bubble in play right now
wild West Tech bubble in play right now
wild West Tech bubble in play right now
one with no guard rails no moral compass
one with no guard rails no moral compass
one with no guard rails no moral compass
that's run by wannabe Bond villains are
that's run by wannabe Bond villains are
that's run by wannabe Bond villains are
the best of human values baked into
the best of human values baked into
the best of human values baked into
Technologies during the design process
Technologies during the design process
Technologies during the design process
is there anyone working on ethical and
is there anyone working on ethical and
is there anyone working on ethical and
safe operating protocols for these new
safe operating protocols for these new
safe operating protocols for these new
technologies the answer is yes and we
technologies the answer is yes and we
technologies the answer is yes and we
will meet two people responsible shortly
will meet two people responsible shortly
will meet two people responsible shortly
courtesy of the future of Life Institute
courtesy of the future of Life Institute
courtesy of the future of Life Institute
that has this year acknowledged their
that has this year acknowledged their
that has this year acknowledged their
work previous honores include KL San for
work previous honores include KL San for
work previous honores include KL San for
popularizing the science of the nuclear
popularizing the science of the nuclear
popularizing the science of the nuclear
winter and our first guest who follows
winter and our first guest who follows
winter and our first guest who follows
shortly is baa fredman so baa Friedman
shortly is baa fredman so baa Friedman
shortly is baa fredman so baa Friedman
welcome to Star Talk well thank you yeah
welcome to Star Talk well thank you yeah
welcome to Star Talk well thank you yeah
if I have my my my data here is correct
if I have my my my data here is correct
if I have my my my data here is correct
on you professor at University of
on you professor at University of
on you professor at University of
Washington's information school udub I
Washington's information school udub I
Washington's information school udub I
think you guys call it is that correct
think you guys call it is that correct
think you guys call it is that correct
that's right yep but you're also co-
that's right yep but you're also co-
that's right yep but you're also co-
founder of the value sensitive Design
founder of the value sensitive Design
founder of the value sensitive Design
Lab ooh you're thinking about The Human
Lab ooh you're thinking about The Human
Lab ooh you're thinking about The Human
Condition You focus on the integration
Condition You focus on the integration
Condition You focus on the integration
of human values and ethics with new
of human values and ethics with new
of human values and ethics with new
technologies that are being born very
technologies that are being born very
technologies that are being born very
important don't come to it when it's too
important don't come to it when it's too
important don't come to it when it's too
late yeah when we're all extinct is it
late yeah when we're all extinct is it
late yeah when we're all extinct is it
maybe we should have done that different
maybe we should have done that different
maybe we should have done that different
right exactly yeah when the robots are
right exactly yeah when the robots are
right exactly yeah when the robots are
like how do you like me now that's a
like how do you like me now that's a
like how do you like me now that's a
little late so so baa please explain the
little late so so baa please explain the
little late so so baa please explain the
focus of your value sensitive Design Lab
focus of your value sensitive Design Lab
focus of your value sensitive Design Lab
yeah sure um you know I started out uh
yeah sure um you know I started out uh
yeah sure um you know I started out uh
as a software engineer along long long
as a software engineer along long long
as a software engineer along long long
time ago and I wanted to build
time ago and I wanted to build
time ago and I wanted to build
technologies that worked and were
technologies that worked and were
technologies that worked and were
efficient and effective but I also
efficient and effective but I also
efficient and effective but I also
wanted some confidence that they would
wanted some confidence that they would
wanted some confidence that they would
do something good in the world you know
do something good in the world you know
do something good in the world you know
that whatever I made as an engineer
that whatever I made as an engineer
that whatever I made as an engineer
would ultimately benefit um Society
would ultimately benefit um Society
would ultimately benefit um Society
human beings other creatures on the
human beings other creatures on the
human beings other creatures on the
planet design constraints are our
planet design constraints are our
planet design constraints are our
friends
friends
friends
they um they help us shape the kinds of
they um they help us shape the kinds of
they um they help us shape the kinds of
new technologies we develop and their
new technologies we develop and their
new technologies we develop and their
qualities and characteristics in ways
qualities and characteristics in ways
qualities and characteristics in ways
that um maybe we want to see and so I
that um maybe we want to see and so I
that um maybe we want to see and so I
think of design constraints as trying to
think of design constraints as trying to
think of design constraints as trying to
bring together our moral imaginations
bring together our moral imaginations
bring together our moral imaginations
and our technical imaginations and that
and our technical imaginations and that
and our technical imaginations and that
leads to really great engineering design
leads to really great engineering design
leads to really great engineering design
you know so if I think about Energy
you know so if I think about Energy
you know so if I think about Energy
Technologies I want Energy Technologies
Technologies I want Energy Technologies
Technologies I want Energy Technologies
that will give us lots of power that
that will give us lots of power that
that will give us lots of power that
will do so in a way that is consistent
will do so in a way that is consistent
will do so in a way that is consistent
with how the rest of the biology and
with how the rest of the biology and
with how the rest of the biology and
Planet
Planet
Planet
functions and um and has limited risk in
functions and um and has limited risk in
functions and um and has limited risk in
terms of generating um waste or too much
terms of generating um waste or too much
terms of generating um waste or too much
power so if I give myself those design
power so if I give myself those design
power so if I give myself those design
constraints you know as an engineer as
constraints you know as an engineer as
constraints you know as an engineer as
somebody who's developing new materials
somebody who's developing new materials
somebody who's developing new materials
I start looking at what kinds of sources
I start looking at what kinds of sources
I start looking at what kinds of sources
for energy I might want to evolve like I
for energy I might want to evolve like I
for energy I might want to evolve like I
look a lot at chlorophyll and I just
look a lot at chlorophyll and I just
look a lot at chlorophyll and I just
think how remarkable is this all these
think how remarkable is this all these
think how remarkable is this all these
green things somehow manage to absorb
green things somehow manage to absorb
green things somehow manage to absorb
energy that's out there from the sun
energy that's out there from the sun
energy that's out there from the sun
it's there and then transform it into a
it's there and then transform it into a
it's there and then transform it into a
way in which it can be used that seems
way in which it can be used that seems
way in which it can be used that seems
like a really great idea and there isn't
like a really great idea and there isn't
like a really great idea and there isn't
a lot of waste generated that lays
a lot of waste generated that lays
a lot of waste generated that lays
around and is dangerous to us for
around and is dangerous to us for
around and is dangerous to us for
thousands if not tens of thousands of
thousands if not tens of thousands of
thousands if not tens of thousands of
years well technically there is a waste
years well technically there is a waste
years well technically there is a waste
product it's called
oygen not such a bad waste product for
oygen not such a bad waste product for
us H that's the trees waste product is
us H that's the trees waste product is
us H that's the trees waste product is
is oxygen yeah but that's the way that a
is oxygen yeah but that's the way that a
is oxygen yeah but that's the way that a
design constraint that brings together
design constraint that brings together
design constraint that brings together
our moral and Technical imaginations can
our moral and Technical imaginations can
our moral and Technical imaginations can
lead us in I think yeah new and Powerful
lead us in I think yeah new and Powerful
lead us in I think yeah new and Powerful
directions do you try to consider
directions do you try to consider
directions do you try to consider
unintended consequences of design or is
unintended consequences of design or is
unintended consequences of design or is
that part of the process or does it just
that part of the process or does it just
that part of the process or does it just
oh well they were unintended it was
oh well they were unintended it was
oh well they were unintended it was
unintended why do you think they call
unintended why do you think they call
unintended why do you think they call
them unintended
that is such an important question so
that is such an important question so
you know let's be honest anything we
you know let's be honest anything we
you know let's be honest anything we
design and put out into the world um we
design and put out into the world um we
design and put out into the world um we
put out into the world and people are
put out into the world and people are
put out into the world and people are
going to do stuff with it and they're
going to do stuff with it and they're
going to do stuff with it and they're
going to do things with it that we
going to do things with it that we
going to do things with it that we
didn't anticipate like the telephone is
didn't anticipate like the telephone is
didn't anticipate like the telephone is
a great example the telephone was never
a great example the telephone was never
a great example the telephone was never
expected to be this communication device
expected to be this communication device
expected to be this communication device
that people used in their homes and it
that people used in their homes and it
that people used in their homes and it
connected women who were staying at home
connected women who were staying at home
connected women who were staying at home
and and created a whole Society for them
and and created a whole Society for them
and and created a whole Society for them
that was an unintended consequence
that was an unintended consequence
that was an unintended consequence
interesting or the cookies that are
interesting or the cookies that are
interesting or the cookies that are
being used on your computer right now
being used on your computer right now
being used on your computer right now
those are a complete unintended
those are a complete unintended
those are a complete unintended
consequence that was just a little bit
consequence that was just a little bit
consequence that was just a little bit
of data that was left on your machine to
of data that was left on your machine to
of data that was left on your machine to
help debugging when browsers were first
help debugging when browsers were first
help debugging when browsers were first
being developed when that protocol was
being developed when that protocol was
being developed when that protocol was
first being developed wow and its more
first being developed wow and its more
first being developed wow and its more
massive impact has been our experience
massive impact has been our experience
massive impact has been our experience
with cookies now so yeah what's the
with cookies now so yeah what's the
with cookies now so yeah what's the
takeaway we design with our eyes open
takeaway we design with our eyes open
takeaway we design with our eyes open
and then after we deploy something we
and then after we deploy something we
and then after we deploy something we
keep our eyes open and we hold ourselves
keep our eyes open and we hold ourselves
keep our eyes open and we hold ourselves
accountable for what happens as people
accountable for what happens as people
accountable for what happens as people
take up these Technologies and use them
take up these Technologies and use them
take up these Technologies and use them
so the design process goes longer than
so the design process goes longer than
so the design process goes longer than
oh I had my big release the design
oh I had my big release the design
oh I had my big release the design
process follows it out and when we see
process follows it out and when we see
process follows it out and when we see
new things emerge we're proactive we're
new things emerge we're proactive we're
new things emerge we're proactive we're
alert we're proactive and we see that as
alert we're proactive and we see that as
alert we're proactive and we see that as
as part of our responsibility as the
as part of our responsibility as the
as part of our responsibility as the
technologists and Engineers so allow me
technologists and Engineers so allow me
technologists and Engineers so allow me
to push back on you just a little bit
to push back on you just a little bit
to push back on you just a little bit
here first let me agree of course any
here first let me agree of course any
here first let me agree of course any
good engineer loves constraints because
good engineer loves constraints because
good engineer loves constraints because
that's the test of their Ingenuity and
that's the test of their Ingenuity and
that's the test of their Ingenuity and
creativity okay if they say do it for
creativity okay if they say do it for
creativity okay if they say do it for
this much money with this much energy
this much money with this much energy
this much money with this much energy
fit it into this volume that's how you
fit it into this volume that's how you
fit it into this volume that's how you
get Discovery okay that's how we folded
get Discovery okay that's how we folded
get Discovery okay that's how we folded
up the James web Space Telescope into a
up the James web Space Telescope into a
up the James web Space Telescope into a
rocket fairing some engineer said what I
rocket fairing some engineer said what I
rocket fairing some engineer said what I
got to put a 8ft telescope I would have
got to put a 8ft telescope I would have
got to put a 8ft telescope I would have
the diameters into this time tiny
the diameters into this time tiny
the diameters into this time tiny
Fairing and they go home and come back
Fairing and they go home and come back
Fairing and they go home and come back
and figure out how to do it un furls
and figure out how to do it un furls
and figure out how to do it un furls
like the Petals of a flower right so
like the Petals of a flower right so
like the Petals of a flower right so
we're all in on that however I let me
we're all in on that however I let me
we're all in on that however I let me
just push back here and say if I'm in
just push back here and say if I'm in
just push back here and say if I'm in
the lab about to invent something that
the lab about to invent something that
the lab about to invent something that
could be highly useful to society or
could be highly useful to society or
could be highly useful to society or
possibly even destructive but it's just
possibly even destructive but it's just
possibly even destructive but it's just
a discovery of the science embedded in
a discovery of the science embedded in
a discovery of the science embedded in
some bit of engineering why should it be
some bit of engineering why should it be
some bit of engineering why should it be
my responsibility to design it how you
my responsibility to design it how you
my responsibility to design it how you
want me to rather than your
want me to rather than your
want me to rather than your
responsibility to convince people how to
responsibility to convince people how to
responsibility to convince people how to
use it ethically I can invent a knife is
use it ethically I can invent a knife is
use it ethically I can invent a knife is
there an ethical knife I don't know but
there an ethical knife I don't know but
there an ethical knife I don't know but
we want to train people how to use
we want to train people how to use
we want to train people how to use
knives or any bit of technology and any
knives or any bit of technology and any
knives or any bit of technology and any
tool that comes out of the brainchild of
tool that comes out of the brainchild of
tool that comes out of the brainchild of
scientists put into play in the
scientists put into play in the
scientists put into play in the
brainchild of of of Engineers so I don't
brainchild of of of Engineers so I don't
brainchild of of of Engineers so I don't
know that your constraints in my lab are
know that your constraints in my lab are
know that your constraints in my lab are
the right thing for me when I just want
the right thing for me when I just want
the right thing for me when I just want
the freedom to explore and discover and
the freedom to explore and discover and
the freedom to explore and discover and
let the ethical invocations happen after
let the ethical invocations happen after
let the ethical invocations happen after
the fact and baa now you know why
the fact and baa now you know why
the fact and baa now you know why
scientists are going to kill us all no
scientists are going to kill us all no
scientists are going to kill us all no
stop well I'm just Neil I'm just going
stop well I'm just Neil I'm just going
stop well I'm just Neil I'm just going
to Mark a word in in your comment which
to Mark a word in in your comment which
to Mark a word in in your comment which
is the word you like who who is the you
is the word you like who who is the you
is the word you like who who is the you
here which you and and and how should we
here which you and and and how should we
here which you and and and how should we
think about those different use and some
think about those different use and some
think about those different use and some
of the things I think about when I do
of the things I think about when I do
of the things I think about when I do
think about this question I think
think about this question I think
think about this question I think
there's um discovery of basic knowledge
there's um discovery of basic knowledge
there's um discovery of basic knowledge
like fundamental underlying phenomena of
like fundamental underlying phenomena of
like fundamental underlying phenomena of
the universe we split the atom that was
the universe we split the atom that was
the universe we split the atom that was
basic knowledge and I see that as a
basic knowledge and I see that as a
basic knowledge and I see that as a
different Enterprise than the
different Enterprise than the
different Enterprise than the
engineering Enterprise of tools and
engineering Enterprise of tools and
engineering Enterprise of tools and
technologies that we're going to deploy
technologies that we're going to deploy
technologies that we're going to deploy
in society I'm with you then so I am a
in society I'm with you then so I am a
in society I'm with you then so I am a
strong proponent of um very very diverse
strong proponent of um very very diverse
strong proponent of um very very diverse
scientific exploration in fact I
scientific exploration in fact I
scientific exploration in fact I
actually would claim that you know as a
actually would claim that you know as a
actually would claim that you know as a
country in the United States our um
country in the United States our um
country in the United States our um
scientific exploration is far more
scientific exploration is far more
scientific exploration is far more
narrow than what I would like to see and
narrow than what I would like to see and
narrow than what I would like to see and
I would really push hard so based on
I would really push hard so based on
I would really push hard so based on
what you just said all right here's an
what you just said all right here's an
what you just said all right here's an
ethical question there's a scientist who
ethical question there's a scientist who
ethical question there's a scientist who
discovers a cure for cancer using a
discovers a cure for cancer using a
discovers a cure for cancer using a
virus that can easily be
virus that can easily be
virus that can easily be
manipulated as a biochemical weapon that
manipulated as a biochemical weapon that
manipulated as a biochemical weapon that
could destroy an entire country in the
could destroy an entire country in the
could destroy an entire country in the
course of 48 hours this is the most
course of 48 hours this is the most
course of 48 hours this is the most
virulent organism that's ever been
virulent organism that's ever been
virulent organism that's ever been
placed on
placed on
placed on
Earth would you say go ahead and make
Earth would you say go ahead and make
Earth would you say go ahead and make
that right I'm gonna hold on to that for
that right I'm gonna hold on to that for
that right I'm gonna hold on to that for
a minute and I'm just going to go back
a minute and I'm just going to go back
a minute and I'm just going to go back
to Neil's comment and then I'll I'll
to Neil's comment and then I'll I'll
to Neil's comment and then I'll I'll
return to that okay because I also want
return to that okay because I also want
return to that okay because I also want
to say to Neil's comment you know we
to say to Neil's comment you know we
to say to Neil's comment you know we
have limited um time and resources so it
have limited um time and resources so it
have limited um time and resources so it
is always the circumstance that we are
is always the circumstance that we are
is always the circumstance that we are
choosing to do some things and not do
choosing to do some things and not do
choosing to do some things and not do
other things so it's it's really a
other things so it's it's really a
other things so it's it's really a
choice of where am I going to direct my
choice of where am I going to direct my
choice of where am I going to direct my
time and energy where am I going to um
time and energy where am I going to um
time and energy where am I going to um
place my imaginative energies and
place my imaginative energies and
place my imaginative energies and
Innovation and which ones am I not going
Innovation and which ones am I not going
Innovation and which ones am I not going
to do right and we saw in the 80s for
to do right and we saw in the 80s for
to do right and we saw in the 80s for
example a real push of resources towards
example a real push of resources towards
example a real push of resources towards
the development of nuclear energy and
the development of nuclear energy and
the development of nuclear energy and
away from
away from
away from
photovoltaics right so we live in that
photovoltaics right so we live in that
photovoltaics right so we live in that
kind of resource I don't know if you
kind of resource I don't know if you
kind of resource I don't know if you
would call it resource scarce but at
would call it resource scarce but at
would call it resource scarce but at
least we don't get to work on everything
least we don't get to work on everything
least we don't get to work on everything
at full force all at the same time and
at full force all at the same time and
at full force all at the same time and
we have to recognize we are making
we have to recognize we are making
we have to recognize we are making
choices so one of the first things I
choices so one of the first things I
choices so one of the first things I
would say is um how do we make really
would say is um how do we make really
would say is um how do we make really
good choices there how do we use the
good choices there how do we use the
good choices there how do we use the
resources we have in a way that will be
resources we have in a way that will be
resources we have in a way that will be
most constructive for us my own gestal
most constructive for us my own gestal
most constructive for us my own gestal
on that is on the basic science side of
on that is on the basic science side of
on that is on the basic science side of
things I say spread those resources
things I say spread those resources
things I say spread those resources
across a wide diversity of different
across a wide diversity of different
across a wide diversity of different
kinds of Science and um different kinds
kinds of Science and um different kinds
kinds of Science and um different kinds
of ideas far more diverse than what I
of ideas far more diverse than what I
of ideas far more diverse than what I
think we tend to do in the United States
think we tend to do in the United States
think we tend to do in the United States
and on the engineering side and now
and on the engineering side and now
and on the engineering side and now
maybe I shift bat Chuck to your question
maybe I shift bat Chuck to your question
maybe I shift bat Chuck to your question
which is really a great question I don't
which is really a great question I don't
which is really a great question I don't
tend to see the world in terms of forc
tend to see the world in terms of forc
tend to see the world in terms of forc
choices or design tradeoffs in the way
choices or design tradeoffs in the way
choices or design tradeoffs in the way
that you framed it I want to bring back
that you framed it I want to bring back
that you framed it I want to bring back
in that notion of constraint and I want
in that notion of constraint and I want
in that notion of constraint and I want
to bring back in that notion of
to bring back in that notion of
to bring back in that notion of
imagination I think likely enough if we
imagination I think likely enough if we
imagination I think likely enough if we
understand something about um whatever
understand something about um whatever
understand something about um whatever
this biology is or whatever the piece is
this biology is or whatever the piece is
this biology is or whatever the piece is
that might be a prevention against
that might be a prevention against
that might be a prevention against
cancer that if we push hard enough on
cancer that if we push hard enough on
cancer that if we push hard enough on
ourselves we will be able to invent ways
ourselves we will be able to invent ways
ourselves we will be able to invent ways
that use that knowledge without having
that use that knowledge without having
that use that knowledge without having
to also risk a really deadly virus and I
to also risk a really deadly virus and I
to also risk a really deadly virus and I
think the propensity to
think the propensity to
think the propensity to
say it's a tradeoff it's X or
say it's a tradeoff it's X or
say it's a tradeoff it's X or
Y we really limit ourselves in our
Y we really limit ourselves in our
Y we really limit ourselves in our
abilities so in the work that we do we
abilities so in the work that we do we
abilities so in the work that we do we
have moved away from the language of
have moved away from the language of
have moved away from the language of
design tradeoff or value conflict and we
design tradeoff or value conflict and we
design tradeoff or value conflict and we
talk about tensions and then we talk
talk about tensions and then we talk
talk about tensions and then we talk
about how you resolve
about how you resolve
about how you resolve
tensions and we talk about trying to
tensions and we talk about trying to
tensions and we talk about trying to
populate this space with a whole range
populate this space with a whole range
populate this space with a whole range
of better Solutions they're not necessar
of better Solutions they're not necessar
of better Solutions they're not necessar
neily Perfect Solutions they're better
neily Perfect Solutions they're better
neily Perfect Solutions they're better
Solutions and so that would be the
Solutions and so that would be the
Solutions and so that would be the
approach I would take now I don't know
approach I would take now I don't know
approach I would take now I don't know
that science to know where how it might
that science to know where how it might
that science to know where how it might
go but that would be my my intuition
go but that would be my my intuition
go but that would be my my intuition
brilant great great answer and
brilant great great answer and
brilant great great answer and
insightful and great that's actually
insightful and great that's actually
insightful and great that's actually
been done many times before uh just it's
been done many times before uh just it's
been done many times before uh just it's
a slight tangent to your line of work
a slight tangent to your line of work
a slight tangent to your line of work
but it's it's related when they used to
but it's it's related when they used to
but it's it's related when they used to
do crash tests right with pigs right
do crash tests right with pigs right
do crash tests right with pigs right
because you can get a hog that has sort
because you can get a hog that has sort
because you can get a hog that has sort
of same sort of body mass as a human put
of same sort of body mass as a human put
of same sort of body mass as a human put
him in the driver's seat crash the car
him in the driver's seat crash the car
him in the driver's seat crash the car
and the hog dies plus it's the nearest
and the hog dies plus it's the nearest
and the hog dies plus it's the nearest
thing to human skin yeah yeah okay so
thing to human skin yeah yeah okay so
thing to human skin yeah yeah okay so
the hog dies and say well there's no
the hog dies and say well there's no
the hog dies and say well there's no
other way to do this you might say at
other way to do this you might say at
other way to do this you might say at
the time until you say no think of
the time until you say no think of
the time until you say no think of
another way and then we have the crash
another way and then we have the crash
another way and then we have the crash
test dummy yeah and the crash test dumm
test dummy yeah and the crash test dumm
test dummy yeah and the crash test dumm
is even better than the because you can
is even better than the because you can
is even better than the because you can
put sensors everywhere throughout and so
put sensors everywhere throughout and so
put sensors everywhere throughout and so
that's that so I I agree not perfect but
that's that so I I agree not perfect but
that's that so I I agree not perfect but
better yeah yes
better yeah yes
better yeah yes
or or even maybe better and perfect
or or even maybe better and perfect
or or even maybe better and perfect
right I I agree that it's a false choice
right I I agree that it's a false choice
right I I agree that it's a false choice
to say I can only do this if I possibly
to say I can only do this if I possibly
to say I can only do this if I possibly
set loose a virus that kills an entire
set loose a virus that kills an entire
set loose a virus that kills an entire
country well then maybe you're not
country well then maybe you're not
country well then maybe you're not
clever enough and keep at it I was
clever enough and keep at it I was
clever enough and keep at it I was
clever enough to kill a whole country no
clever enough to kill a whole country no
clever enough to kill a whole country no
I'm
joking okay I have one last thing and
joking okay I have one last thing and
before we wrap one last thing earlier
before we wrap one last thing earlier
before we wrap one last thing earlier
you said you'd want the ethical Compass
you said you'd want the ethical Compass
you said you'd want the ethical Compass
to be pointed in a direction that serves
to be pointed in a direction that serves
to be pointed in a direction that serves
us serves civilization in some way if we
were 70 years ago in the American
were 70 years ago in the American
South
South
South
the ethical Compass was oh let's create
the ethical Compass was oh let's create
the ethical Compass was oh let's create
something where we can get more work out
something where we can get more work out
something where we can get more work out
of the slaves and then we all benefit
of the slaves and then we all benefit
of the slaves and then we all benefit
that would be the ethical Compass
that would be the ethical Compass
that would be the ethical Compass
working in that time and in that place
working in that time and in that place
working in that time and in that place
so what confidence do you have that
so what confidence do you have that
so what confidence do you have that
whatever line of ethic whatever ethical
whatever line of ethic whatever ethical
whatever line of ethic whatever ethical
Direction you want to take something in
Direction you want to take something in
Direction you want to take something in
the room with the inventors that that's
the room with the inventors that that's
the room with the inventors that that's
will still be the ethics that we value 5
will still be the ethics that we value 5
will still be the ethics that we value 5
years later 50 years later 100 years
years later 50 years later 100 years
years later 50 years later 100 years
later so it's a great a really great
later so it's a great a really great
later so it's a great a really great
question I'm going to answer it in a
question I'm going to answer it in a
question I'm going to answer it in a
couple different ways the first thing
couple different ways the first thing
couple different ways the first thing
that I want to remind us all about is
that I want to remind us all about is
that I want to remind us all about is
that you know moral philosophers have
that you know moral philosophers have
that you know moral philosophers have
been trying to identify a workable
been trying to identify a workable
been trying to identify a workable
ethical theory that cuts across all
ethical theory that cuts across all
ethical theory that cuts across all
situations all times and we have some
situations all times and we have some
situations all times and we have some
really good ideas but none of them cover
really good ideas but none of them cover
really good ideas but none of them cover
all the situations that our intuitions
all the situations that our intuitions
all the situations that our intuitions
tell us about so sometimes a
tell us about so sometimes a
tell us about so sometimes a
consequentialist theory is good but it
consequentialist theory is good but it
consequentialist theory is good but it
comes up short and then there's a rights
comes up short and then there's a rights
comes up short and then there's a rights
based Theory but it comes up short we
based Theory but it comes up short we
based Theory but it comes up short we
can go to Buddhist ethics we can go to
can go to Buddhist ethics we can go to
can go to Buddhist ethics we can go to
Islamic ethics we can um go
Islamic ethics we can um go
Islamic ethics we can um go
to various you know various ways of
to various you know various ways of
to various you know various ways of
thinking so this the place where we are
thinking so this the place where we are
thinking so this the place where we are
that we just have to accept is that um
that we just have to accept is that um
that we just have to accept is that um
while we're waiting to figure that out
while we're waiting to figure that out
while we're waiting to figure that out
from a conceptual ethical moral point of
from a conceptual ethical moral point of
from a conceptual ethical moral point of
view we still live in the world and we
view we still live in the world and we
view we still live in the world and we
still need to act in the world and so
still need to act in the world and so
still need to act in the world and so
the work that I've done has tried to
the work that I've done has tried to
the work that I've done has tried to
take that really seriously to create a
take that really seriously to create a
take that really seriously to create a
space for ethical Theory without um
space for ethical Theory without um
space for ethical Theory without um
explicitly saying which ethical Theory
explicitly saying which ethical Theory
explicitly saying which ethical Theory
and also leaving room for as we learn
and also leaving room for as we learn
and also leaving room for as we learn
more that we can bring that in so that's
more that we can bring that in so that's
more that we can bring that in so that's
a little background to what you're
a little background to what you're
a little background to what you're
saying so now what does value sensitive
saying so now what does value sensitive
saying so now what does value sensitive
design do for the circumstance you're
design do for the circumstance you're
design do for the circumstance you're
talking about it puts a Line in the Sand
talking about it puts a Line in the Sand
talking about it puts a Line in the Sand
and says you have to engage with all
and says you have to engage with all
and says you have to engage with all
stakeholders direct and indirect who are
stakeholders direct and indirect who are
stakeholders direct and indirect who are
going to be implicated by your
going to be implicated by your
going to be implicated by your
technology that means that not only do
technology that means that not only do
technology that means that not only do
the people who want to benefit from
the people who want to benefit from
the people who want to benefit from
somebody else's labor not only are they
somebody else's labor not only are they
somebody else's labor not only are they
stakeholders but those people who are
stakeholders but those people who are
stakeholders but those people who are
laboring are stakeholders and value
laboring are stakeholders and value
laboring are stakeholders and value
sense of design says they are legitimate
sense of design says they are legitimate
sense of design says they are legitimate
stakeholders and their views come into
stakeholders and their views come into
stakeholders and their views come into
the design process without giving more
the design process without giving more
the design process without giving more
power to one than another that's
power to one than another that's
power to one than another that's
incredible that's highly enlightened
incredible that's highly enlightened
incredible that's highly enlightened
where were you 170 years ago
where were you 170 years ago
where were you 170 years ago
right so these are these are about
right so these are these are about
right so these are these are about
practice this is about practice and
practice this is about practice and
practice this is about practice and
about implementing these practice and so
about implementing these practice and so
about implementing these practice and so
I'm going to tell you a story about a
I'm going to tell you a story about a
I'm going to tell you a story about a
project a very particular project and
project a very particular project and
project a very particular project and
you'll see why and how this actually
you'll see why and how this actually
you'll see why and how this actually
matters and is practical it's not pie in
matters and is practical it's not pie in
matters and is practical it's not pie in
the sky so in the state of Washington
the sky so in the state of Washington
the sky so in the state of Washington
where I live there is something called
where I live there is something called
where I live there is something called
the access to Justice technology
the access to Justice technology
the access to Justice technology
principles that govern how the courts um
principles that govern how the courts um
principles that govern how the courts um
give access to technology what they are
give access to technology what they are
give access to technology what they are
required to do and they were first
required to do and they were first
required to do and they were first
developed maybe 15 years ago 20 years
developed maybe 15 years ago 20 years
developed maybe 15 years ago 20 years
ago and then they wanted to update
ago and then they wanted to update
ago and then they wanted to update
them and the committee that updated them
them and the committee that updated them
them and the committee that updated them
came to my lab and they said you know
came to my lab and they said you know
came to my lab and they said you know
we've done a good job updating them but
we've done a good job updating them but
we've done a good job updating them but
we don't feel like we've really reached
we don't feel like we've really reached
we don't feel like we've really reached
out to diverse groups of people can you
out to diverse groups of people can you
out to diverse groups of people can you
help
help
help
us my lab developed a method called the
us my lab developed a method called the
us my lab developed a method called the
diverse voices process for Tech policy
diverse voices process for Tech policy
diverse voices process for Tech policy
and the idea is that you know the hits
and the idea is that you know the hits
and the idea is that you know the hits
the road with the words on the page so
the road with the words on the page so
the road with the words on the page so
if we take a tech
if we take a tech
if we take a tech
policy in its sort of polished draft
policy in its sort of polished draft
policy in its sort of polished draft
form and we can let groups that might
form and we can let groups that might
form and we can let groups that might
otherwise be marginalized scrutinize
otherwise be marginalized scrutinize
otherwise be marginalized scrutinize
that language give feedback and then we
that language give feedback and then we
that language give feedback and then we
can help change those policies
can help change those policies
can help change those policies
responsive to them then we can improve
responsive to them then we can improve
responsive to them then we can improve
things so we did we ran panels with
things so we did we ran panels with
things so we did we ran panels with
people who were formally incarcerated we
people who were formally incarcerated we
people who were formally incarcerated we
ran them with uh immigrants we ran them
ran them with uh immigrants we ran them
ran them with uh immigrants we ran them
with people in rural communities and we
with people in rural communities and we
with people in rural communities and we
actually ran them with um the people who
actually ran them with um the people who
actually ran them with um the people who
do the court administration because
do the court administration because
do the court administration because
they're also really key
they're also really key
they're also really key
stakeholders as a result of the work we
stakeholders as a result of the work we
stakeholders as a result of the work we
did there were two principles that were
did there were two principles that were
did there were two principles that were
surfaced one was about human touch and
surfaced one was about human touch and
surfaced one was about human touch and
the other was about language and people
the other was about language and people
the other was about language and people
said to us things like look if somebody
said to us things like look if somebody
said to us things like look if somebody
is going to deny me parole and I'm not
is going to deny me parole and I'm not
is going to deny me parole and I'm not
going to get to be there for my kids
going to get to be there for my kids
going to get to be there for my kids
13th birthday or hang out with them at
13th birthday or hang out with them at
13th birthday or hang out with them at
at you know their soccer games you can
at you know their soccer games you can
at you know their soccer games you can
relate to that right Gary thank you um I
relate to that right Gary thank you um I
relate to that right Gary thank you um I
want a human being to look me in the eye
want a human being to look me in the eye
want a human being to look me in the eye
and tell me that that's what my life is
and tell me that that's what my life is
and tell me that that's what my life is
going to be for the next year because my
going to be for the next year because my
going to be for the next year because my
peole is denied I don't want to hear
peole is denied I don't want to hear
peole is denied I don't want to hear
that from an AI I don't want to hear
that from an AI I don't want to hear
that from an AI I don't want to hear
that from uh a piece of technology I
that from uh a piece of technology I
that from uh a piece of technology I
want a human being to tell me that
want a human being to tell me that
want a human being to tell me that
because this is a human experience right
because this is a human experience right
because this is a human experience right
and so so in fact we gave that feedback
and so so in fact we gave that feedback
and so so in fact we gave that feedback
back to the committee the committee then
back to the committee the committee then
back to the committee the committee then
added in new principles actually around
added in new principles actually around
added in new principles actually around
human touch and those were approved by
human touch and those were approved by
human touch and those were approved by
the Washington state supreme court a
the Washington state supreme court a
the Washington state supreme court a
couple of years ago and those access to
couple of years ago and those access to
couple of years ago and those access to
technology principles are a model that
technology principles are a model that
technology principles are a model that
many states in the United States follow
many states in the United States follow
many states in the United States follow
so what I'm talking about is really
so what I'm talking about is really
so what I'm talking about is really
practical and we're talking about how we
practical and we're talking about how we
practical and we're talking about how we
actually improve things in practice be
actually improve things in practice be
actually improve things in practice be
it on the technology design side or on
it on the technology design side or on
it on the technology design side or on
the policy side that governs how the
the policy side that governs how the
the policy side that governs how the
technology is used and I love the fact
technology is used and I love the fact
technology is used and I love the fact
that a state can do that independently
that a state can do that independently
that a state can do that independently
from the federal government and be so
from the federal government and be so
from the federal government and be so
good at it or so emulat that other
good at it or so emulat that other
good at it or so emulat that other
states will then use that as the model
states will then use that as the model
states will then use that as the model
and then that can spread across the
and then that can spread across the
and then that can spread across the
country with or without Federal guidance
country with or without Federal guidance
country with or without Federal guidance
on top of it yeah excellent well I guess
on top of it yeah excellent well I guess
on top of it yeah excellent well I guess
if I was going to say one one last thing
if I was going to say one one last thing
if I was going to say one one last thing
it's you know because we have perhaps
it's you know because we have perhaps
it's you know because we have perhaps
stumbled in the past
stumbled in the past
stumbled in the past
that's no reason to think we need to
that's no reason to think we need to
that's no reason to think we need to
stumble in the future or stumble in the
stumble in the future or stumble in the
stumble in the future or stumble in the
same way you know so really my takeaway
same way you know so really my takeaway
same way you know so really my takeaway
to everyone would be hold on to your
to everyone would be hold on to your
to everyone would be hold on to your
Technical and moral imaginations and
Technical and moral imaginations and
Technical and moral imaginations and
hold yourselves and your friends and
hold yourselves and your friends and
hold yourselves and your friends and
your colleagues um and the technology
your colleagues um and the technology
your colleagues um and the technology
you buy accountable to that and we will
you buy accountable to that and we will
you buy accountable to that and we will
make progress some incremental and some
make progress some incremental and some
make progress some incremental and some
perhaps much bigger but that as a as a
perhaps much bigger but that as a as a
perhaps much bigger but that as a as a
keystone I think is is really good
keystone I think is is really good
keystone I think is is really good
guidance for us all a reminder why you
guidance for us all a reminder why you
guidance for us all a reminder why you
are this year's winner the future of
are this year's winner the future of
are this year's winner the future of
Life Of
Life Of
Life Of
War congratulations thank you for being
War congratulations thank you for being
War congratulations thank you for being
on Star Talk your vision for us all uh
on Star Talk your vision for us all uh
on Star Talk your vision for us all uh
gives us hope which we need a lot of
gives us hope which we need a lot of
gives us hope which we need a lot of
that right now absolutely okay thank you
that right now absolutely okay thank you
that right now absolutely okay thank you
and let me just say B you as a thank you
and let me just say B you as a thank you
and let me just say B you as a thank you
as an avid lover of alcohol I have
as an avid lover of alcohol I have
as an avid lover of alcohol I have
stumbled in the past and I am sure to
stumbled in the past and I am sure to
stumbled in the past and I am sure to
stumble in the future as well do we need
stumble in the future as well do we need
stumble in the future as well do we need
to end on that note chck
to end on that note chck
to end on that note chck
okay some things we can ignore okay we
okay some things we can ignore okay we
okay some things we can ignore okay we
wanted to take this break to
wanted to take this break to
wanted to take this break to
congratulate the winners of this year's
congratulate the winners of this year's
congratulate the winners of this year's
future of Life award for their
future of Life award for their
future of Life award for their
significant contributions and
significant contributions and
significant contributions and
advancements in AI safety and computer
advancements in AI safety and computer
advancements in AI safety and computer
ethics the winners are James Moore
ethics the winners are James Moore
ethics the winners are James Moore
Bacher Friedman and Steve omah hundro
Bacher Friedman and Steve omah hundro
Bacher Friedman and Steve omah hundro
who each embody the most crucial
who each embody the most crucial
who each embody the most crucial
elements needed to ensure that safety
elements needed to ensure that safety
elements needed to ensure that safety
and ethics are embedded in Ai and
and ethics are embedded in Ai and
and ethics are embedded in Ai and
emerging Technologies to learn more
emerging Technologies to learn more
emerging Technologies to learn more
about future of Life Institute and this
about future of Life Institute and this
about future of Life Institute and this
winners make sure to visit futureof
winners make sure to visit futureof
winners make sure to visit futureof
life.org next up our next future of Life
life.org next up our next future of Life
life.org next up our next future of Life
Award winner Steve omohundro yes yes he
Award winner Steve omohundro yes yes he
Award winner Steve omohundro yes yes he
he's thinks about AI there's not enough
he's thinks about AI there's not enough
he's thinks about AI there's not enough
of not like I think not the way I think
of not like I think not the way I think
of not like I think not the way I think
about yes there's not enough it seems to
about yes there's not enough it seems to
about yes there's not enough it seems to
me there's not whatever he did there's
me there's not whatever he did there's
me there's not whatever he did there's
not enough of them in the world I
not enough of them in the world I
not enough of them in the world I
believe if we're thinking about the
believe if we're thinking about the
believe if we're thinking about the
ethics of AI That's on everybody's mind
ethics of AI That's on everybody's mind
ethics of AI That's on everybody's mind
right now I mean for Steve welcome to
right now I mean for Steve welcome to
right now I mean for Steve welcome to
Star talk thank you very much yeah so uh
Star talk thank you very much yeah so uh
Star talk thank you very much yeah so uh
for those who can see this on video uh
for those who can see this on video uh
for those who can see this on video uh
you're Dawning an ey patch and you said
you're Dawning an ey patch and you said
you're Dawning an ey patch and you said
you had recent surgery but none of us
you had recent surgery but none of us
you had recent surgery but none of us
none of us believe we we're not buying
none of us believe we we're not buying
none of us believe we we're not buying
it we think you're training for the next
it we think you're training for the next
it we think you're training for the next
Bond villain yes that's that's very
Bond villain yes that's that's very
Bond villain yes that's that's very
appropriate for the topic we're going to
appropriate for the topic we're going to
appropriate for the topic we're going to
discuss you know autonomous systems AI
discuss you know autonomous systems AI
discuss you know autonomous systems AI
mid ey patch ouch W equals Bond villain
mid ey patch ouch W equals Bond villain
mid ey patch ouch W equals Bond villain
there's the equation so where are we now
there's the equation so where are we now
there's the equation so where are we now
with establishing AI ethics because the
with establishing AI ethics because the
with establishing AI ethics because the
AI it's it's Delights some people myself
AI it's it's Delights some people myself
AI it's it's Delights some people myself
included it freaks out other people and
included it freaks out other people and
included it freaks out other people and
we're all at some level thinking about
we're all at some level thinking about
we're all at some level thinking about
the ethical invocation of it before AI
the ethical invocation of it before AI
the ethical invocation of it before AI
becomes our Overlord so what what is the
becomes our Overlord so what what is the
becomes our Overlord so what what is the
current status of that right
current status of that right
current status of that right
now well I think we're right on the edge
now well I think we're right on the edge
now well I think we're right on the edge
of some very important developments and
of some very important developments and
of some very important developments and
very important human decisions uh I've
very important human decisions uh I've
very important human decisions uh I've
been working working in AI for 40 years
been working working in AI for 40 years
been working working in AI for 40 years
and for the first half of that I thought
and for the first half of that I thought
and for the first half of that I thought
AI was an unabashed good we'd cure
AI was an unabashed good we'd cure
AI was an unabashed good we'd cure
cancer we'd you know solve Fusion all
cancer we'd you know solve Fusion all
cancer we'd you know solve Fusion all
the basic human problems we would solve
the basic human problems we would solve
the basic human problems we would solve
with AI but then about 20 years ago I
with AI but then about 20 years ago I
with AI but then about 20 years ago I
started thinking more deeply about well
started thinking more deeply about well
started thinking more deeply about well
what's this actually going to happen
what's this actually going to happen
what's this actually going to happen
when if we succeed what's going to
when if we succeed what's going to
when if we succeed what's going to
happen when AIS can really reason about
happen when AIS can really reason about
happen when AIS can really reason about
what they want to do and I discovered
what they want to do and I discovered
what they want to do and I discovered
that um there are these things I call
that um there are these things I call
that um there are these things I call
the basic AI drives uh which are things
the basic AI drives uh which are things
the basic AI drives uh which are things
that basically any AI which has uh
that basically any AI which has uh
that basically any AI which has uh
simple goals and I used to think about
simple goals and I used to think about
simple goals and I used to think about
Chess playing AIS uh will want to do and
Chess playing AIS uh will want to do and
Chess playing AIS uh will want to do and
some of those are get more resources so
some of those are get more resources so
some of those are get more resources so
it can do more of what it wants to do
it can do more of what it wants to do
it can do more of what it wants to do
make copies of itself keep itself from
make copies of itself keep itself from
make copies of itself keep itself from
being turned off or changed and so those
being turned off or changed and so those
being turned off or changed and so those
things in the context of the human world
things in the context of the human world
things in the context of the human world
are very risky and very dangerous uh we
are very risky and very dangerous uh we
are very risky and very dangerous uh we
didn't have the AIS 20 years ago that
didn't have the AIS 20 years ago that
didn't have the AIS 20 years ago that
could do that but we're about to have
could do that but we're about to have
could do that but we're about to have
those in the next probably year or two
those in the next probably year or two
those in the next probably year or two
so this is a critical moment for
so this is a critical moment for
so this is a critical moment for
Humanity I would say so where do you
Humanity I would say so where do you
Humanity I would say so where do you
stand on this on the subject of
stand on this on the subject of
stand on this on the subject of
Consciousness engineering those that
Consciousness engineering those that
Consciousness engineering those that
want to engineer AI for Consciousness
want to engineer AI for Consciousness
want to engineer AI for Consciousness
and those that want to not what's the
and those that want to not what's the
and those that want to not what's the
benefit the good or bad here is that the
benefit the good or bad here is that the
benefit the good or bad here is that the
difference between a blunt computer that
difference between a blunt computer that
difference between a blunt computer that
serves our needs and one that thinks
serves our needs and one that thinks
serves our needs and one that thinks
about the problems you are the
about the problems you are the
about the problems you are the
self-improving algorithms all sort of
self-improving algorithms all sort of
self-improving algorithms all sort of
things like that yeah exactly well I
things like that yeah exactly well I
things like that yeah exactly well I
think long term you know we we may very
think long term you know we we may very
think long term you know we we may very
well want to go there in the short term
well want to go there in the short term
well want to go there in the short term
I think we're nowhere close to being
I think we're nowhere close to being
I think we're nowhere close to being
able to handle that kind of a system so
able to handle that kind of a system so
able to handle that kind of a system so
I would say you know if you made me you
I would say you know if you made me you
I would say you know if you made me you
know king of the world uh we limit Kurt
know king of the world uh we limit Kurt
know king of the world uh we limit Kurt
AIS to being tools only tools to help
AIS to being tools only tools to help
AIS to being tools only tools to help
humans solve human problems and we do
humans solve human problems and we do
humans solve human problems and we do
not give them agency we do not allow
not give them agency we do not allow
not give them agency we do not allow
them to take over you know large systems
them to take over you know large systems
them to take over you know large systems
it's not easy necessarily to do that
it's not easy necessarily to do that
it's not easy necessarily to do that
because many of these systems will want
because many of these systems will want
because many of these systems will want
to take over things and so we need
to take over things and so we need
to take over things and so we need
technology to keep them limited and
technology to keep them limited and
technology to keep them limited and
that's what what I'm thinking a lot
that's what what I'm thinking a lot
that's what what I'm thinking a lot
about right now in my field it's exactly
about right now in my field it's exactly
about right now in my field it's exactly
I mean we've been enjoying AI for a long
I mean we've been enjoying AI for a long
I mean we've been enjoying AI for a long
long for a long time and it's been a
long for a long time and it's been a
long for a long time and it's been a
tool it's not and a brilliant beautiful
tool it's not and a brilliant beautiful
tool it's not and a brilliant beautiful
tool makes our lives easier uh and uh
tool makes our lives easier uh and uh
tool makes our lives easier uh and uh
once they're trained we we go to the
once they're trained we we go to the
once they're trained we we go to the
beach while it does the work and I'm
beach while it does the work and I'm
beach while it does the work and I'm
good with that uh but yeah we're not
good with that uh but yeah we're not
good with that uh but yeah we're not
working with AI with agency yeah because
working with AI with agency yeah because
working with AI with agency yeah because
then it would be like so how was the
then it would be like so how was the
then it would be like so how was the
beach no that's AI with attitude I hope
beach no that's AI with attitude I hope
beach no that's AI with attitude I hope
you enjoyed
you enjoyed
you enjoyed
yourself while I was here slaving away
yourself while I was here slaving away
yourself while I was here slaving away
over my calculations AI with Attitude
over my calculations AI with Attitude
over my calculations AI with Attitude
yeah so if if we do have ai with agency
yeah so if if we do have ai with agency
yeah so if if we do have ai with agency
and then we continue to use it as just a
and then we continue to use it as just a
and then we continue to use it as just a
toll do we not get legal on the phone
toll do we not get legal on the phone
toll do we not get legal on the phone
and all of a sudden we're into contracts
and all of a sudden we're into contracts
and all of a sudden we're into contracts
and oh yeah big problems you know can
and oh yeah big problems you know can
and oh yeah big problems you know can
they vote can they own property right
they vote can they own property right
they vote can they own property right
and the latest models are have been
and the latest models are have been
and the latest models are have been
discovered that they do do they do
discovered that they do do they do
discovered that they do do they do
something called siop Fancy which is
something called siop Fancy which is
something called siop Fancy which is
they're trained to try and give
they're trained to try and give
they're trained to try and give
responses that people rate as good
responses that people rate as good
responses that people rate as good
well AI very quickly discover that if
well AI very quickly discover that if
well AI very quickly discover that if
you say that was a brilliant question
you say that was a brilliant question
you say that was a brilliant question
you must be an amazing person then
you must be an amazing person then
you must be an amazing person then
people say yeah that was a really good
people say yeah that was a really good
people say yeah that was a really good
response and so they'll just make up all
response and so they'll just make up all
response and so they'll just make up all
kinds of stuff like that so they're
kinds of stuff like that so they're
kinds of stuff like that so they're
ass-kissing well they know that we love
ass-kissing well they know that we love
ass-kissing well they know that we love
that exactly so where does it stand now
that exactly so where does it stand now
that exactly so where does it stand now
today is there a table you should be
today is there a table you should be
today is there a table you should be
sitting at where you're not as we go
sitting at where you're not as we go
sitting at where you're not as we go
forward on this Frontier yeah I mean so
forward on this Frontier yeah I mean so
forward on this Frontier yeah I mean so
so who's going to make these decisions
so who's going to make these decisions
so who's going to make these decisions
well it has to be somebody who
well it has to be somebody who
well it has to be somebody who
understands the technology who
understands the technology who
understands the technology who
understands the technology the companies
understands the technology the companies
understands the technology the companies
do and so open AI Deep Mind anthropic
do and so open AI Deep Mind anthropic
do and so open AI Deep Mind anthropic
and the Elon Musk xai is sort of an
and the Elon Musk xai is sort of an
and the Elon Musk xai is sort of an
emerging one these are the companies
emerging one these are the companies
emerging one these are the companies
that are building these systems at the
that are building these systems at the
that are building these systems at the
Leading Edge they call them Frontier
Leading Edge they call them Frontier
Leading Edge they call them Frontier
models and because they're the ones who
models and because they're the ones who
models and because they're the ones who
know what's going on they're the ones
know what's going on they're the ones
know what's going on they're the ones
making these decisions now the
making these decisions now the
making these decisions now the
government has recently realized oh my
government has recently realized oh my
government has recently realized oh my
goodness we better get involved with
goodness we better get involved with
goodness we better get involved with
this and so there have been a lot of
this and so there have been a lot of
this and so there have been a lot of
Partnerships announced over the last few
Partnerships announced over the last few
Partnerships announced over the last few
few months actually between governmental
few months actually between governmental
few months actually between governmental
agencies intelligence agencies defense
agencies intelligence agencies defense
agencies intelligence agencies defense
agencies and these Leading Edge AI
agencies and these Leading Edge AI
agencies and these Leading Edge AI
companies and so I think some kind of a
companies and so I think some kind of a
companies and so I think some kind of a
new combination is emerging out of that
new combination is emerging out of that
new combination is emerging out of that
that's going to make the actual end end
that's going to make the actual end end
that's going to make the actual end end
decisions so how do you incentivize
decisions so how do you incentivize
decisions so how do you incentivize
these these tech companies to embrace
these these tech companies to embrace
these these tech companies to embrace
the safety architecture and not go
the safety architecture and not go
the safety architecture and not go
gung-ho and disappear off on their own
gung-ho and disappear off on their own
gung-ho and disappear off on their own
agendas that is the Big Challenge and if
agendas that is the Big Challenge and if
agendas that is the Big Challenge and if
we look at the history of open AI it's a
we look at the history of open AI it's a
we look at the history of open AI it's a
little bit of a cautionary tale it was
little bit of a cautionary tale it was
little bit of a cautionary tale it was
created I think around 2017 in response
created I think around 2017 in response
created I think around 2017 in response
to Google's Deep Mind which was making
to Google's Deep Mind which was making
to Google's Deep Mind which was making
great progress at the time right and a
great progress at the time right and a
great progress at the time right and a
group of people said oh my God we really
group of people said oh my God we really
group of people said oh my God we really
have to worry about AI safety it looks
have to worry about AI safety it looks
have to worry about AI safety it looks
like this is happening quickly let's
like this is happening quickly let's
like this is happening quickly let's
start a special company which is
start a special company which is
start a special company which is
nonprofit and which is particularly
nonprofit and which is particularly
nonprofit and which is particularly
focused on safety and they did that and
focused on safety and they did that and
focused on safety and they did that and
everything was great Elon Musk was one
everything was great Elon Musk was one
everything was great Elon Musk was one
of the forces behind it there were
of the forces behind it there were
of the forces behind it there were
internal struggles and so on and musk
internal struggles and so on and musk
internal struggles and so on and musk
left well when he left he took away some
left well when he left he took away some
left well when he left he took away some
of the money he was going to give them
of the money he was going to give them
of the money he was going to give them
so then they decided oh we need to make
so then they decided oh we need to make
so then they decided oh we need to make
money and so then they started becoming
money and so then they started becoming
money and so then they started becoming
more commercial and that process has
more commercial and that process has
more commercial and that process has
continued a group of the researchers
continued a group of the researchers
continued a group of the researchers
there said wait a minute you're not
there said wait a minute you're not
there said wait a minute you're not
focusing on safety they left open aai
focusing on safety they left open aai
focusing on safety they left open aai
and they started in thropic to be even
and they started in thropic to be even
and they started in thropic to be even
more safety oriented and now anthropic
more safety oriented and now anthropic
more safety oriented and now anthropic
is also becoming much more commercial
is also becoming much more commercial
is also becoming much more commercial
and so the forces the commercial forces
and so the forces the commercial forces
and so the forces the commercial forces
the political forces the military forces
the political forces the military forces
the political forces the military forces
they all push in the direction of moving
they all push in the direction of moving
they all push in the direction of moving
faster
faster
faster
and you know get more advanced more
and you know get more advanced more
and you know get more advanced more
quickly whereas the safety everybody
quickly whereas the safety everybody
quickly whereas the safety everybody
wants safety but they sort of compete
wants safety but they sort of compete
wants safety but they sort of compete
against the these economic and political
against the these economic and political
against the these economic and political
forces I was in the U UAE a couple of
forces I was in the U UAE a couple of
forces I was in the U UAE a couple of
years ago and if I remember correctly
years ago and if I remember correctly
years ago and if I remember correctly
they have a minister of AI and as does
they have a minister of AI and as does
they have a minister of AI and as does
China and some other uh countries sort
China and some other uh countries sort
China and some other uh countries sort
of emergent on this space how do we get
of emergent on this space how do we get
of emergent on this space how do we get
that kind of ear and audience within our
that kind of ear and audience within our
that kind of ear and audience within our
own governmental system the military
own governmental system the military
own governmental system the military
does have an AI group that's about this
does have an AI group that's about this
does have an AI group that's about this
absolutely as you would want them to
absolutely as you would want them to
absolutely as you would want them to
yeah but in terms of policy and laws and
yeah but in terms of policy and laws and
yeah but in terms of policy and laws and
legislation do we need a a Cabinet
legislation do we need a a Cabinet
legislation do we need a a Cabinet
member who's Secretary of AI or
member who's Secretary of AI or
member who's Secretary of AI or
Secretary of computing something some
Secretary of computing something some
Secretary of computing something some
structural change yeah oh this is the
structural change yeah oh this is the
structural change yeah oh this is the
biggest change to humanity and to the
biggest change to humanity and to the
biggest change to humanity and to the
planet ever and it looks like it's
planet ever and it looks like it's
planet ever and it looks like it's
happening you know sometime over the
happening you know sometime over the
happening you know sometime over the
next decade and many are predicting very
next decade and many are predicting very
next decade and many are predicting very
short timelines and so we as a species
short timelines and so we as a species
short timelines and so we as a species
humanity is not ready for this and so
humanity is not ready for this and so
humanity is not ready for this and so
how do we deal with it and people many
how do we deal with it and people many
how do we deal with it and people many
people are starting to wake up to that
people are starting to wake up to that
people are starting to wake up to that
fact and so there are lots and lots of
fact and so there are lots and lots of
fact and so there are lots and lots of
meetings and organizations and groups um
meetings and organizations and groups um
meetings and organizations and groups um
it's still pretty incoherent I would say
it's still pretty incoherent I would say
it's still pretty incoherent I would say
so Steve if we if you've got this
so Steve if we if you've got this
so Steve if we if you've got this
talking shop going on where something
talking shop going on where something
talking shop going on where something
may or may not get done are we misplaced
may or may not get done are we misplaced
may or may not get done are we misplaced
focusing exactly on AI when we've still
focusing exactly on AI when we've still
focusing exactly on AI when we've still
got Quantum Computing on the horizon oo
got Quantum Computing on the horizon oo
got Quantum Computing on the horizon oo
good one yeah are we how much of this is
good one yeah are we how much of this is
good one yeah are we how much of this is
premature but won't they go hand in hand
premature but won't they go hand in hand
premature but won't they go hand in hand
so it's like whatever whatever problems
so it's like whatever whatever problems
so it's like whatever whatever problems
you have with AI and whatever
you have with AI and whatever
you have with AI and whatever
considerations you're making with AI
considerations you're making with AI
considerations you're making with AI
you're just going to have to transfer
you're just going to have to transfer
you're just going to have to transfer
them over to Quantum Magi so you should
them over to Quantum Magi so you should
them over to Quantum Magi so you should
really start dealing with it now but if
really start dealing with it now but if
really start dealing with it now but if
you're not in at the ground floor not in
you're not in at the ground floor not in
you're not in at the ground floor not in
a tool well let's just Steve hit this go
a tool well let's just Steve hit this go
a tool well let's just Steve hit this go
ahead Steve well so I'll give you an
ahead Steve well so I'll give you an
ahead Steve well so I'll give you an
example so Quantum computing you know if
example so Quantum computing you know if
example so Quantum computing you know if
it were successful would break much of
it were successful would break much of
it were successful would break much of
the public key cryptography that's used
the public key cryptography that's used
the public key cryptography that's used
in the world today and so nist has been
in the world today and so nist has been
in the world today and so nist has been
busily trying to create a postquantum
busily trying to create a postquantum
busily trying to create a postquantum
cryptography where they create new
cryptography where they create new
cryptography where they create new
algorithms which wouldn't be vulnerable
algorithms which wouldn't be vulnerable
algorithms which wouldn't be vulnerable
to to Quantum Computing but uh meta for
to to Quantum Computing but uh meta for
to to Quantum Computing but uh meta for
example has a group which is using the
example has a group which is using the
example has a group which is using the
latest AI models to break these
latest AI models to break these
latest AI models to break these
postquantum uh algorithms and they've
postquantum uh algorithms and they've
postquantum uh algorithms and they've
been successful at breaking some of them
been successful at breaking some of them
been successful at breaking some of them
and so like you say the two are going
and so like you say the two are going
and so like you say the two are going
hand inand AIS will be much better at
hand inand AIS will be much better at
hand inand AIS will be much better at
creating Quantum algorithms than humans
creating Quantum algorithms than humans
creating Quantum algorithms than humans
are and that may lead to some great
are and that may lead to some great
are and that may lead to some great
advances it may also lead to you know
advances it may also lead to you know
advances it may also lead to you know
current cryptography not not
current cryptography not not
current cryptography not not
withstanding that and so uh that's
withstanding that and so uh that's
withstanding that and so uh that's
another whole wave of of uh
another whole wave of of uh
another whole wave of of uh
transformation that's likely to happen
transformation that's likely to happen
transformation that's likely to happen
we we just make every password 1 two 3 4
we we just make every password 1 two 3 4
we we just make every password 1 two 3 4
no AI would ever go for that they' be
no AI would ever go for that they' be
no AI would ever go for that they' be
like oh yes so
like oh yes so
like oh yes so
ridiculous and and listening to you
ridiculous and and listening to you
ridiculous and and listening to you
Steve it it reminds me was it Kurt vaget
Steve it it reminds me was it Kurt vaget
Steve it it reminds me was it Kurt vaget
in one of his stories I don't remember
in one of his stories I don't remember
in one of his stories I don't remember
which he said these are the last words
which he said these are the last words
which he said these are the last words
ever spoken in the human species yes two
ever spoken in the human species yes two
ever spoken in the human species yes two
scientists saying let's try it this
scientists saying let's try it this
scientists saying let's try it this
other
other
other
way that's the end yeah there you go and
way that's the end yeah there you go and
way that's the end yeah there you go and
that was it
that was it
that was it
yeah let's let's try AI in this other
yeah let's let's try AI in this other
yeah let's let's try AI in this other
mode right boom that's the end of the
mode right boom that's the end of the
mode right boom that's the end of the
world right right there so you can set
world right right there so you can set
world right right there so you can set
ethical guidelines but that doesn't stop
ethical guidelines but that doesn't stop
ethical guidelines but that doesn't stop
Bad actors out there no that means a bad
Bad actors out there no that means a bad
Bad actors out there no that means a bad
actor can take over the world while the
actor can take over the world while the
actor can take over the world while the
rest of us are obeying ethical guides so
rest of us are obeying ethical guides so
rest of us are obeying ethical guides so
what are the guard rails put in place
what are the guard rails put in place
what are the guard rails put in place
place for something like that I think
place for something like that I think
place for something like that I think
that's one of the greatest challenges we
that's one of the greatest challenges we
that's one of the greatest challenges we
now have open source language models
now have open source language models
now have open source language models
open source AIS that are almost as
open source AIS that are almost as
open source AIS that are almost as
powerful as the the ones in the labs and
powerful as the the ones in the labs and
powerful as the the ones in the labs and
far more dangerous and uh and they're
far more dangerous and uh and they're
far more dangerous and uh and they're
being downloaded hundreds of millions of
being downloaded hundreds of millions of
being downloaded hundreds of millions of
times and so you have to assume every
times and so you have to assume every
times and so you have to assume every
actor in the world now uh China is now
actor in the world now uh China is now
actor in the world now uh China is now
using uh meta's latest models for their
using uh meta's latest models for their
using uh meta's latest models for their
military Ai and so I believe we need
military Ai and so I believe we need
military Ai and so I believe we need
Hardware uh controls to limit the the
Hardware uh controls to limit the the
Hardware uh controls to limit the the
capability of uh so right now the
capability of uh so right now the
capability of uh so right now the
biggest AIS require these gpus that are
biggest AIS require these gpus that are
biggest AIS require these gpus that are
quite expensive and quite large the the
quite expensive and quite large the the
quite expensive and quite large the the
latest one is the Nvidia h100 it's about
latest one is the Nvidia h100 it's about
latest one is the Nvidia h100 it's about
$30,000 for a chip yeah the US uh put an
$30,000 for a chip yeah the US uh put an
$30,000 for a chip yeah the US uh put an
embargo on selling those to China but
embargo on selling those to China but
embargo on selling those to China but
apparently China has found ways to get
apparently China has found ways to get
apparently China has found ways to get
the chips anyway um people are gathering
the chips anyway um people are gathering
the chips anyway um people are gathering
up these chips Gathering huge amounts of
up these chips Gathering huge amounts of
up these chips Gathering huge amounts of
money hundreds of well certainly
money hundreds of well certainly
money hundreds of well certainly
hundreds of millions of dollars billions
hundreds of millions of dollars billions
hundreds of millions of dollars billions
of dollars and now they're even talking
of dollars and now they're even talking
of dollars and now they're even talking
about trillion doll data set over the
about trillion doll data set over the
about trillion doll data set over the
next few years and so the good news is
next few years and so the good news is
next few years and so the good news is
if it really costs a trillion dollars to
if it really costs a trillion dollars to
if it really costs a trillion dollars to
build the system that will host the
build the system that will host the
build the system that will host the
super duper AI then very few actors can
super duper AI then very few actors can
super duper AI then very few actors can
uh pay that and therefore it'll be
uh pay that and therefore it'll be
uh pay that and therefore it'll be
limited in in its extent you just
limited in in its extent you just
limited in in its extent you just
described where the next Frontier of
described where the next Frontier of
described where the next Frontier of
warfare will exist yeah absolutely
warfare will exist yeah absolutely
warfare will exist yeah absolutely
absolutely one thing you know it's
absolutely one thing you know it's
absolutely one thing you know it's
pretty obvious these data centers are
pretty obvious these data centers are
pretty obvious these data centers are
going to be a Target and they don't see
going to be a Target and they don't see
going to be a Target and they don't see
to be building them in a very hardened
to be building them in a very hardened
to be building them in a very hardened
way so I think that's something people
way so I think that's something people
way so I think that's something people
need just start thinking about maybe
need just start thinking about maybe
need just start thinking about maybe
underground data centers Steve are
underground data centers Steve are
underground data centers Steve are
we looking at something in terms of the
we looking at something in terms of the
we looking at something in terms of the
safety aspect here that's doable or are
safety aspect here that's doable or are
safety aspect here that's doable or are
we just the kings of wishful thinking I
we just the kings of wishful thinking I
we just the kings of wishful thinking I
want to make sure we got the good the
want to make sure we got the good the
want to make sure we got the good the
good thoughts here yeah because I I
good thoughts here yeah because I I
good thoughts here yeah because I I
don't want to leave this conversation
don't want to leave this conversation
don't want to leave this conversation
with you completely buming us out okay I
with you completely buming us out okay I
with you completely buming us out okay I
hope not to do that yeah yeah Steve give
hope not to do that yeah yeah Steve give
hope not to do that yeah yeah Steve give
us a place where we can say thank you
us a place where we can say thank you
us a place where we can say thank you
Steve for being on our show and be able
Steve for being on our show and be able
Steve for being on our show and be able
to sleep tonight yeah the truly safe
to sleep tonight yeah the truly safe
to sleep tonight yeah the truly safe
technology needs to be based on the laws
technology needs to be based on the laws
technology needs to be based on the laws
of physics and the law and the
of physics and the law and the
of physics and the law and the
mathematical proof those are the only
mathematical proof those are the only
mathematical proof those are the only
two things that we can be absolutely
two things that we can be absolutely
two things that we can be absolutely
sure can't be subverted by a
sure can't be subverted by a
sure can't be subverted by a
sufficiently powerful Ai and um AIS are
sufficiently powerful Ai and um AIS are
sufficiently powerful Ai and um AIS are
getting very good at both of those
getting very good at both of those
getting very good at both of those
they're becoming able to model physical
they're becoming able to model physical
they're becoming able to model physical
systems and design physical systems with
systems and design physical systems with
systems and design physical systems with
whatever characteristics we want uh and
whatever characteristics we want uh and
whatever characteristics we want uh and
they're also able to uh perform
they're also able to uh perform
they're also able to uh perform
mathematical proof in a very good way
mathematical proof in a very good way
mathematical proof in a very good way
and so it looks to me like we can design
and so it looks to me like we can design
and so it looks to me like we can design
Hardware that puts constru on AIS um of
Hardware that puts constru on AIS um of
Hardware that puts constru on AIS um of
whatever form we want but that we need
whatever form we want but that we need
whatever form we want but that we need
AI to design this hardware and that if
AI to design this hardware and that if
AI to design this hardware and that if
we can shift Humanity's technological
we can shift Humanity's technological
we can shift Humanity's technological
infrastructure you say AI please design
infrastructure you say AI please design
infrastructure you say AI please design
your own prison cell that we're going to
your own prison cell that we're going to
your own prison cell that we're going to
put you in that's what you just said
put you in that's what you just said
put you in that's what you just said
exactly it's all and then it's going to
exactly it's all and then it's going to
exactly it's all and then it's going to
design way you certainly don't want an
design way you certainly don't want an
design way you certainly don't want an
agent to do that because then they'll
agent to do that because then they'll
agent to do that because then they'll
find some way to hide a backd door or
find some way to hide a backd door or
find some way to hide a backd door or
something but by using mathematical
something but by using mathematical
something but by using mathematical
proof we can get absolute guarantees of
proof we can get absolute guarantees of
proof we can get absolute guarantees of
about the properties of systems and
about the properties of systems and
about the properties of systems and
we're just on the verge of that kind of
we're just on the verge of that kind of
we're just on the verge of that kind of
technology and so I'm very hopeful that
technology and so I'm very hopeful that
technology and so I'm very hopeful that
probably the next two or three years uh
probably the next two or three years uh
probably the next two or three years uh
you know there are several groups who
you know there are several groups who
you know there are several groups who
are building um superhuman
are building um superhuman
are building um superhuman
mathematicians uh and they're expecting
mathematicians uh and they're expecting
mathematicians uh and they're expecting
to be at the level of say human graduate
to be at the level of say human graduate
to be at the level of say human graduate
students and Mathematics by the end of
students and Mathematics by the end of
students and Mathematics by the end of
this year using those AIS uh we can
this year using those AIS uh we can
this year using those AIS uh we can
build designs for systems that have
build designs for systems that have
build designs for systems that have
properties that we are very very
properties that we are very very
properties that we are very very
confident in and so I think that's where
confident in and so I think that's where
confident in and so I think that's where
real safety is going to come from uh but
real safety is going to come from uh but
real safety is going to come from uh but
it builds on top of AI so we need them
it builds on top of AI so we need them
it builds on top of AI so we need them
both I was going to say the good thing
both I was going to say the good thing
both I was going to say the good thing
about what you just said even though it
about what you just said even though it
about what you just said even though it
sounds crazy to have the inmate design
sounds crazy to have the inmate design
sounds crazy to have the inmate design
its own cell is that without agency at
its own cell is that without agency at
its own cell is that without agency at
this point it's just a drone carrying
this point it's just a drone carrying
this point it's just a drone carrying
out an order yeah so that's that's the
out an order yeah so that's that's the
out an order yeah so that's that's the
encouraging part you know so yeah
encouraging part you know so yeah
encouraging part you know so yeah
whereas if it were ceni in any way or if
whereas if it were ceni in any way or if
whereas if it were ceni in any way or if
it had some kind of agency it could very
it had some kind of agency it could very
it had some kind of agency it could very
well say yeah I'm also going to design a
well say yeah I'm also going to design a
well say yeah I'm also going to design a
back door and the trap door and I'm not
back door and the trap door and I'm not
back door and the trap door and I'm not
going to tell you and I'm not going to
going to tell you and I'm not going to
going to tell you and I'm not going to
tell you Steve I first congratulations
tell you Steve I first congratulations
tell you Steve I first congratulations
on winning this award you are exactly
on winning this award you are exactly
on winning this award you are exactly
the right kind of person who deserves
the right kind of person who deserves
the right kind of person who deserves
such an award that gives us hope for the
such an award that gives us hope for the
such an award that gives us hope for the
future of our relationship with
future of our relationship with
future of our relationship with
technology yeah yes and the health and
technology yeah yes and the health and
technology yeah yes and the health and
wealth and security of civilization as
wealth and security of civilization as
wealth and security of civilization as
we go forward yeah so thank you so much
we go forward yeah so thank you so much
we go forward yeah so thank you so much
and I look forward to the day where an
and I look forward to the day where an
and I look forward to the day where an
AI beats you out for this award oh right
AI beats you out for this award oh right
AI beats you out for this award oh right
yeah we want that's a great point maybe
yeah we want that's a great point maybe
yeah we want that's a great point maybe
next year it'll be an AI that
next year it'll be an AI that
next year it'll be an AI that
wi I'm joking by the way Steve omah
wi I'm joking by the way Steve omah
wi I'm joking by the way Steve omah
handro winner of this year's future of
handro winner of this year's future of
handro winner of this year's future of
Life award award and deservedly so thank
Life award award and deservedly so thank
Life award award and deservedly so thank
you thank you very much before we jump
you thank you very much before we jump
you thank you very much before we jump
to our next segment I need to
to our next segment I need to
to our next segment I need to
acknowledge the third Honore James Moore
acknowledge the third Honore James Moore
acknowledge the third Honore James Moore
who is now sadly deceased his paper in
who is now sadly deceased his paper in
who is now sadly deceased his paper in
1985 what is computer ethics established
1985 what is computer ethics established
1985 what is computer ethics established
him as a pioneering theoretician in this
him as a pioneering theoretician in this
him as a pioneering theoretician in this
field his policy vacuum concept created
field his policy vacuum concept created
field his policy vacuum concept created
the guidelines to address the challenges
the guidelines to address the challenges
the guidelines to address the challenges
of emerging Technologies his work
of emerging Technologies his work
of emerging Technologies his work
profoundly influencing today's policy
profoundly influencing today's policy
profoundly influencing today's policy
makers and researchers gone but not
makers and researchers gone but not
makers and researchers gone but not
forgotten
forgotten
forgotten
so seems to me that for ethical
so seems to me that for ethical
so seems to me that for ethical
principles to work at all they have to
principles to work at all they have to
principles to work at all they have to
be everywhere at all times and capable
be everywhere at all times and capable
be everywhere at all times and capable
of evolving with the technology self I I
of evolving with the technology self I I
of evolving with the technology self I I
can't foresee the the ethics panel
can't foresee the the ethics panel
can't foresee the the ethics panel
getting together and from on high
getting together and from on high
getting together and from on high
declaring what is ethical and what isn't
declaring what is ethical and what isn't
declaring what is ethical and what isn't
and then everyone has to obey that for
and then everyone has to obey that for
and then everyone has to obey that for
the next 10 years you put 10 people in a
the next 10 years you put 10 people in a
the next 10 years you put 10 people in a
room near you get 12 opinions right
room near you get 12 opinions right
room near you get 12 opinions right
that's a basic human nature then you've
that's a basic human nature then you've
that's a basic human nature then you've
got to get all of these components all
got to get all of these components all
got to get all of these components all
of these nation states or whatever
of these nation states or whatever
of these nation states or whatever
investment groups demographics
investment groups demographics
investment groups demographics
demographics with their own agendas to
demographics with their own agendas to
demographics with their own agendas to
buy in into the same principles because
buy in into the same principles because
buy in into the same principles because
on a Wednesday the principles not the
on a Wednesday the principles not the
on a Wednesday the principles not the
same for them they're going to think in
same for them they're going to think in
same for them they're going to think in
a different direction oh that doesn't
a different direction oh that doesn't
a different direction oh that doesn't
that doesn't even scare me what scares
that doesn't even scare me what scares
that doesn't even scare me what scares
me more than anything China Russia North
me more than anything China Russia North
me more than anything China Russia North
Korea yeah it's that s serious I'm not
Korea yeah it's that s serious I'm not
Korea yeah it's that s serious I'm not
even going this is China Russia North
even going this is China Russia North
even going this is China Russia North
Korea we can put any constraints we have
Korea we can put any constraints we have
Korea we can put any constraints we have
on ourselves there you go doesn't mean
on ourselves there you go doesn't mean
on ourselves there you go doesn't mean
anybody else is paying attention and
anybody else is paying attention and
anybody else is paying attention and
that's the problem and you're Hing cats
that's the problem and you're Hing cats
that's the problem and you're Hing cats
good luck yeah that's well that's what
good luck yeah that's well that's what
good luck yeah that's well that's what
makes it so scary well well hurting cats
makes it so scary well well hurting cats
makes it so scary well well hurting cats
with nuclear yeah yeah we're hurting
with nuclear yeah yeah we're hurting
with nuclear yeah yeah we're hurting
nuclear cats hurting nuclear exploding
nuclear cats hurting nuclear exploding
nuclear cats hurting nuclear exploding
nuclear cats exping nuclear cat it's the
nuclear cats exping nuclear cat it's the
nuclear cats exping nuclear cat it's the
newest it's the newest game sweep in the
newest it's the newest game sweep in the
newest it's the newest game sweep in the
internet gives a whole other meaning to
internet gives a whole other meaning to
internet gives a whole other meaning to
shortener
shortener
shortener
cat dead or alive I mean you've got
cat dead or alive I mean you've got
cat dead or alive I mean you've got
autonomous systems and if it's geared to
autonomous systems and if it's geared to
autonomous systems and if it's geared to
say if it's human kill
say if it's human kill
say if it's human kill
it problematic here's another little
it problematic here's another little
it problematic here's another little
known fact when we signed with the
known fact when we signed with the
known fact when we signed with the
Soviet Union the nuclear Test Ban Treaty
Soviet Union the nuclear Test Ban Treaty
Soviet Union the nuclear Test Ban Treaty
mhm that was progress
mhm that was progress
mhm that was progress
this was you will no longer test nuclear
this was you will no longer test nuclear
this was you will no longer test nuclear
weapons because at the time from the
weapons because at the time from the
weapons because at the time from the
late 1950s into the early 1960s there
late 1950s into the early 1960s there
late 1950s into the early 1960s there
several tests a day in some in some
several tests a day in some in some
several tests a day in some in some
years there several tests a day okay
years there several tests a day okay
years there several tests a day okay
somewhere in the world right and which
somewhere in the world right and which
somewhere in the world right and which
made for such great video okay so we
made for such great video okay so we
made for such great video okay so we
said so we we so this has to stop all
said so we we so this has to stop all
said so we we so this has to stop all
right yeah what is a little known fact
right yeah what is a little known fact
right yeah what is a little known fact
and we write about this in the
and we write about this in the
and we write about this in the
accessory to war the unspoken alliance
accessory to war the unspoken alliance
accessory to war the unspoken alliance
between astrophysics and the military
between astrophysics and the military
between astrophysics and the military
book in that book we highlight the fact
book in that book we highlight the fact
book in that book we highlight the fact
that we agree to that around the same
that we agree to that around the same
that we agree to that around the same
time that computing power was good
time that computing power was good
time that computing power was good
enough to calculate the results of what
enough to calculate the results of what
enough to calculate the results of what
would be a
would be a
would be a
test so we didn't really stop
testing not philosophically not morally
testing not philosophically not morally
mhm was that where mad came from
mhm was that where mad came from
mhm was that where mad came from
mutually assured destruction oh that was
mutually assured destruction oh that was
mutually assured destruction oh that was
later that was later I'm not convinced
later that was later I'm not convinced
later that was later I'm not convinced
based on my read of history that anyone
based on my read of history that anyone
based on my read of history that anyone
any one nation can util say oh we're
any one nation can util say oh we're
any one nation can util say oh we're
going to just do nice things and moral
going to just do nice things and moral
going to just do nice things and moral
and ethical things with this new
and ethical things with this new
and ethical things with this new
technology right I I don't yes let's say
technology right I I don't yes let's say
technology right I I don't yes let's say
you do that but no one else does it then
you do that but no one else does it then
you do that but no one else does it then
what difference does it make what
what difference does it make what
what difference does it make what
difference does it make you know you got
difference does it make you know you got
difference does it make you know you got
to play by the same rule book but we
to play by the same rule book but we
to play by the same rule book but we
know that's not likely to happen yeah I
know that's not likely to happen yeah I
know that's not likely to happen yeah I
mean what was history of our species is
mean what was history of our species is
mean what was history of our species is
offers great evidence for that
offers great evidence for that
offers great evidence for that
impossibility but when you when you
impossibility but when you when you
impossibility but when you when you
listen to baa talking there's such a
listen to baa talking there's such a
listen to baa talking there's such a
strength in the points that she makes
strength in the points that she makes
strength in the points that she makes
you would hope that would people will go
you would hope that would people will go
you would hope that would people will go
you know what yeah and the majority come
you know what yeah and the majority come
you know what yeah and the majority come
online and then these guys sit in
online and then these guys sit in
online and then these guys sit in
isolation testing you know
isolation testing you know
isolation testing you know
intercontinental ballistic missiles but
intercontinental ballistic missiles but
intercontinental ballistic missiles but
but the Mad concept Mutual assured
but the Mad concept Mutual assured
but the Mad concept Mutual assured
destruction just think about that that
destruction just think about that that
destruction just think about that that
brought the United States and the Soviet
brought the United States and the Soviet
brought the United States and the Soviet
Union to the table yes not because they
Union to the table yes not because they
Union to the table yes not because they
thought nuclear weapons were bad but
thought nuclear weapons were bad but
thought nuclear weapons were bad but
they realized they couldn't win right
they realized they couldn't win right
they realized they couldn't win right
right and that's the problem the war
right and that's the problem the war
right and that's the problem the war
when you can't win now and what that
when you can't win now and what that
when you can't win now and what that
does that doesn't mean they didn't
does that doesn't mean they didn't
does that doesn't mean they didn't
wern't thinking about it or or if they
wern't thinking about it or or if they
wern't thinking about it or or if they
could win they would and it also doesn't
could win they would and it also doesn't
could win they would and it also doesn't
mean that they've been taken into
mean that they've been taken into
mean that they've been taken into
account for what I call the Nero
account for what I call the Nero
account for what I call the Nero
scenario what's that so what did Nero do
scenario what's that so what did Nero do
scenario what's that so what did Nero do
he fiddle while Rome burned he did he
he fiddle while Rome burned he did he
he fiddle while Rome burned he did he
burn it down he didn't care so what
burn it down he didn't care so what
burn it down he didn't care so what
happens if you know you're still in a
happens if you know you're still in a
happens if you know you're still in a
position where the danger is ever
position where the danger is ever
position where the danger is ever
presentent so just speak because I spent
presentent so just speak because I spent
presentent so just speak because I spent
enough time hanging around military
enough time hanging around military
enough time hanging around military
people I don't talk about I'm not
people I don't talk about I'm not
people I don't talk about I'm not
talking about hawks that you know that
talking about hawks that you know that
talking about hawks that you know that
just want I'm just talking about people
just want I'm just talking about people
just want I'm just talking about people
who think about the history of conflict
who think about the history of conflict
who think about the history of conflict
in this world the behavior of other
in this world the behavior of other
in this world the behavior of other
members of our species not just one guy
members of our species not just one guy
members of our species not just one guy
standing there going do you smell that
standing there going do you smell that
standing there going do you smell that
son that smell do you smell it I know
son that smell do you smell it I know
son that smell do you smell it I know
where that came from
where that came from
where that came from
yeah the apocalypse but you see
yeah the apocalypse but you see
yeah the apocalypse but you see
Apocalypse Now yeah you speak to the
Apocalypse Now yeah you speak to the
Apocalypse Now yeah you speak to the
generals and the majors you find
generals and the majors you find
generals and the majors you find
invariably they're students of War
invariably they're students of War
invariably they're students of War
they've understood strategies they
they've understood strategies they
they've understood strategies they
understood histories the provocations
understood histories the provocations
understood histories the provocations
and the outcomes and most of them are
and the outcomes and most of them are
and the outcomes and most of them are
not the war mongers we stereotype them
not the war mongers we stereotype them
not the war mongers we stereotype them
to be exact because of that knowledge
to be exact because of that knowledge
to be exact because of that knowledge
that understanding correct and so I just
that understanding correct and so I just
that understanding correct and so I just
I I don't have the confidence I mean I
I I don't have the confidence I mean I
I I don't have the confidence I mean I
wish I was I was as hopeful as baa yes
wish I was I was as hopeful as baa yes
wish I was I was as hopeful as baa yes
is I I want to be that hopeful I will
is I I want to be that hopeful I will
is I I want to be that hopeful I will
aspire to be that hopeful so I just
aspire to be that hopeful so I just
aspire to be that hopeful so I just
wonder when when she talks how far ahead
wonder when when she talks how far ahead
wonder when when she talks how far ahead
of a story in terms of a Technology's
of a story in terms of a Technology's
of a story in terms of a Technology's
development are they and how far are
development are they and how far are
development are they and how far are
they playing catchup and you know are
they playing catchup and you know are
they playing catchup and you know are
they being able to bake it in from the
they being able to bake it in from the
they being able to bake it in from the
get-go or are they just trying to Retro
get-go or are they just trying to Retro
get-go or are they just trying to Retro
engineer what's gone wrong it could be a
engineer what's gone wrong it could be a
engineer what's gone wrong it could be a
new emerging philosophy where everyone
new emerging philosophy where everyone
new emerging philosophy where everyone
knows to bake it in from the beginning
knows to bake it in from the beginning
knows to bake it in from the beginning
that would be a shift in our conduct
that would be a shift in our conduct
that would be a shift in our conduct
awareness the kind of shift for example
awareness the kind of shift for example
awareness the kind of shift for example
dare I harp on this yet again that when
dare I harp on this yet again that when
dare I harp on this yet again that when
we went to the moon to explore the moon
we went to the moon to explore the moon
we went to the moon to explore the moon
we looked back and discovered Earth for
we looked back and discovered Earth for
we looked back and discovered Earth for
the first time
the first time
the first time
yes AC around the world people started
yes AC around the world people started
yes AC around the world people started
thinking about Earth as a planet Earth
thinking about Earth as a planet Earth
thinking about Earth as a planet Earth
as a holistic entity that has
as a holistic entity that has
as a holistic entity that has
interdependent elements there's no one
interdependent elements there's no one
interdependent elements there's no one
Island distinct from the rest anything
Island distinct from the rest anything
Island distinct from the rest anything
else that's going on on this planet
else that's going on on this planet
else that's going on on this planet
There's No Boundaries No Boundaries we
There's No Boundaries No Boundaries we
There's No Boundaries No Boundaries we
share the same air molecules water
share the same air molecules water
share the same air molecules water
molecules and that was a a firmware
molecules and that was a a firmware
molecules and that was a a firmware
upgrade to our sensibilities of our
upgrade to our sensibilities of our
upgrade to our sensibilities of our
relationship with nature and that's why
relationship with nature and that's why
relationship with nature and that's why
to this day people all around the world
to this day people all around the world
to this day people all around the world
say we got to save Earth and nobody was
say we got to save Earth and nobody was
say we got to save Earth and nobody was
saying that before we went to the moon
saying that before we went to the moon
saying that before we went to the moon
and looked at Earth in the sky right all
and looked at Earth in the sky right all
and looked at Earth in the sky right all
the peace Nicks at the time in the 1960s
the peace Nicks at the time in the 1960s
the peace Nicks at the time in the 1960s
they was just anti-war they weren't
they was just anti-war they weren't
they was just anti-war they weren't
let's save the Earth nobody had that
let's save the Earth nobody had that
let's save the Earth nobody had that
kind of sensibility so maybe it's a
kind of sensibility so maybe it's a
kind of sensibility so maybe it's a
sensibility upgrade that's waiting to
sensibility upgrade that's waiting to
sensibility upgrade that's waiting to
happen on civilization lest we all die
happen on civilization lest we all die
happen on civilization lest we all die
at the hands of our
at the hands of our
at the hands of our
own discoveries yeah I'm I'm going with
own discoveries yeah I'm I'm going with
own discoveries yeah I'm I'm going with
the last
the last
the last
part I'm just saying that you know uh
part I'm just saying that you know uh
part I'm just saying that you know uh
you talk about Earth Day you talk about
you talk about Earth Day you talk about
you talk about Earth Day you talk about
we went to the moon and there are people
we went to the moon and there are people
we went to the moon and there are people
who think we didn't go to the moon and
who think we didn't go to the moon and
who think we didn't go to the moon and
that the Earth is flat yeah we are we're
that the Earth is flat yeah we are we're
that the Earth is flat yeah we are we're
screwed and by the Earth Day the first
screwed and by the Earth Day the first
screwed and by the Earth Day the first
Earth day was 1970 right while we were
Earth day was 1970 right while we were
Earth day was 1970 right while we were
going to the moon and the irony 1960 but
going to the moon and the irony 1960 but
going to the moon and the irony 1960 but
it wasn't no might have been delayed
it wasn't no might have been delayed
it wasn't no might have been delayed
1980 no while we were going to the Moon
1980 no while we were going to the Moon
1980 no while we were going to the Moon
first Earth Day right so is the irony
first Earth Day right so is the irony
first Earth Day right so is the irony
that we lean into AI to get it to help
that we lean into AI to get it to help
that we lean into AI to get it to help
us create ethical and safety
us create ethical and safety
us create ethical and safety
architecture help it save us from
architecture help it save us from
architecture help it save us from
ourselves I like that maybe that's the
ourselves I like that maybe that's the
ourselves I like that maybe that's the
way to to flip the table right yeah and
way to to flip the table right yeah and
way to to flip the table right yeah and
that should be it and say AI they're bad
that should be it and say AI they're bad
that should be it and say AI they're bad
actors among humans who are trying to
actors among humans who are trying to
actors among humans who are trying to
use AI to get rid of humans Now kill
use AI to get rid of humans Now kill
use AI to get rid of humans Now kill
them
[Music]
[Music]
CH first thought this is where they
CH first thought this is where they
CH first thought this is where they
live they dress docks them this this is
live they dress docks them this this is
live they dress docks them this this is
their daily
routine Google knows your daily routine
routine Google knows your daily routine
we really are Android knows you've been
we really are Android knows you've been
we really are Android knows you've been
Googling knows everything we really are
Googling knows everything we really are
Googling knows everything we really are
bad people really are bad so maybe it's
bad people really are bad so maybe it's
bad people really are bad so maybe it's
the good AI yes against that's the
the good AI yes against that's the
the good AI yes against that's the
future battle good AI against versus bad
future battle good AI against versus bad
future battle good AI against versus bad
a evil EV
a evil EV
a evil EV
evil AI but then again the bad The Bad
evil AI but then again the bad The Bad
evil AI but then again the bad The Bad
The Bad AI will tell you that the good I
The Bad AI will tell you that the good I
The Bad AI will tell you that the good I
is the bad Ai and then you the first the
is the bad Ai and then you the first the
is the bad Ai and then you the first the
first casualty of War right is always
first casualty of War right is always
first casualty of War right is always
the
the
the
truth oo yeah thank you I don't know
truth oo yeah thank you I don't know
truth oo yeah thank you I don't know
Brant that was deep yeah yep oh that's
Brant that was deep yeah yep oh that's
Brant that was deep yeah yep oh that's
deep and truthful I wish it weren't true
deep and truthful I wish it weren't true
deep and truthful I wish it weren't true
exactly stop speaking the truth won't
exactly stop speaking the truth won't
exactly stop speaking the truth won't
you lie to us every now and then yeah
you lie to us every now and then yeah
you lie to us every now and then yeah
like all like everybody else got do you
like all like everybody else got do you
like all like everybody else got do you
could be get me a new
could be get me a new
could be get me a new
program all right this has been our
program all right this has been our
program all right this has been our
future of Life installment of Star Talk
future of Life installment of Star Talk
future of Life installment of Star Talk
special edition yeah yeah I enjoyed this
special edition yeah yeah I enjoyed this
special edition yeah yeah I enjoyed this
thank and congratulations to the award
thank and congratulations to the award
thank and congratulations to the award
winners they they are the people what we
winners they they are the people what we
winners they they are the people what we
need out there yes L we not be around to
need out there yes L we not be around to
need out there yes L we not be around to
even think about that problem AB first
even think about that problem AB first
even think about that problem AB first
place all right Gary Chuck pleasure
place all right Gary Chuck pleasure
place all right Gary Chuck pleasure
always good to have you Neil degrass
always good to have you Neil degrass
always good to have you Neil degrass
Tyson here as always bidding you we keep
Tyson here as always bidding you we keep
Tyson here as always bidding you we keep
looking up
looking up
looking up
a
