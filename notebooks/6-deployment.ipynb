{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f4bc1d",
   "metadata": {},
   "source": [
    "# Deploy chatbot to Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59e68f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/test/Desktop/ironhack_labs/YouTube_ChatBot_Final/notebooks/utils.py:21: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings(openai_api_key=keys[\"OPENAI_API_KEY\"])\n",
      "/Users/test/Desktop/ironhack_labs/YouTube_ChatBot_Final/notebooks/utils.py:27: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0, model=\"gpt-4\", openai_api_key=keys[\"OPENAI_API_KEY\"])\n",
      "/Users/test/Desktop/ironhack_labs/YouTube_ChatBot_Final/notebooks/utils.py:81: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
      "/Users/test/Desktop/ironhack_labs/YouTube_ChatBot_Final/notebooks/utils.py:84: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  return initialize_agent(\n",
      "/opt/anaconda3/envs/cleanenv/lib/python3.10/site-packages/gradio/interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://eaed4364cc5d00a790.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://eaed4364cc5d00a790.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using text input\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hq/l56ghxv518j9wg6pgqkbbvd80000gn/T/ipykernel_32937/572740301.py:46: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  full_answer = agent.run(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: YouTubeTranscriptQA\n",
      "Action Input: who is bill nye?\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/test/Desktop/ironhack_labs/YouTube_ChatBot_Final/notebooks/utils.py:65: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": input_text})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mBill Nye is a popular American science communicator, television presenter, and mechanical engineer. He is best known as the host of the PBS children's science show \"Bill Nye the Science Guy\" (1993‚Äì1998), which aimed to teach a specific topic in science to a preteen audience.\n",
      "\n",
      "Sources:\n",
      "40 - Neil deGrasse Tyson and Bill Nye Catch Up.en.txt\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: Bill Nye is a popular American science communicator, television presenter, and mechanical engineer. He is best known as the host of the PBS children's science show \"Bill Nye the Science Guy\" (1993‚Äì1998), which aimed to teach a specific topic in science to a preteen audience.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Bill Nye, an American science communicator and TV presenter, is renowned for hosting the PBS children's show \"Bill Nye the Science Guy\" (1993‚Äì1998), educating preteens on various science topics.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Imports\n",
    "import gradio as gr\n",
    "import whisper\n",
    "import uuid\n",
    "import os\n",
    "from gtts import gTTS\n",
    "import utils  # Import the whole module so you can reload it\n",
    "import importlib\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "# Then you can safely import the individual functions again\n",
    "from utils import init_qa_chain, get_agent\n",
    "\n",
    "\n",
    "# ‚úÖ Load QA agent\n",
    "qa_chain = init_qa_chain()\n",
    "agent = get_agent(qa_chain)\n",
    "\n",
    "# ‚úÖ Load Whisper model once\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# üîß Utility: Transcribe audio file using Whisper\n",
    "def transcribe_audio_file(audio_file):\n",
    "    print(\"üìù Transcribing audio...\")\n",
    "    result = model.transcribe(audio_file.name)\n",
    "    text = result[\"text\"].strip()\n",
    "    print(f\"üó£Ô∏è Transcribed text: {text}\")\n",
    "    return text\n",
    "\n",
    "# üîä Utility: Generate TTS file using gTTS\n",
    "def generate_tts(text):\n",
    "    filename = f\"{uuid.uuid4().hex}.mp3\"\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    tts.save(filename)\n",
    "    return filename\n",
    "\n",
    "def shorten_text(text, max_ratio=0.5):\n",
    "    prompt = f\"Please shorten the following text to about {int(max_ratio*100)}% of its length, keeping the key information:\\n\\n{text}\"\n",
    "    shortened = agent.run(prompt)\n",
    "    return shortened\n",
    "\n",
    "# üß† Ask the agent\n",
    "def answer_with_sources(question):\n",
    "    prompt = f\"Use the YouTubeTranscriptQA tool to answer this question: {question}\"\n",
    "    full_answer = agent.run(prompt)\n",
    "    short_answer = shorten_text(full_answer)\n",
    "    return short_answer\n",
    "\n",
    "# üß© Gradio logic: handles text or audio\n",
    "def gradio_qa(text_input, audio_input):\n",
    "    if text_input and text_input.strip():\n",
    "        question = text_input.strip()\n",
    "        print(\"‚úÖ Using text input\")\n",
    "    elif audio_input is not None:\n",
    "        question = transcribe_audio_file(audio_input)\n",
    "        print(\"‚úÖ Using audio input\")\n",
    "    else:\n",
    "        return \"Please enter a question or upload audio.\", \"\", None\n",
    "\n",
    "    answer = answer_with_sources(question)\n",
    "    audio_path = generate_tts(answer)\n",
    "    return question, answer, audio_path\n",
    "\n",
    "# üéõÔ∏è Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_qa,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Enter your question (text)\", lines=2, placeholder=\"Type your question here...\"),\n",
    "        gr.Audio(type=\"filepath\", label=\"Or upload your question as audio\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Processed Question\"),\n",
    "        gr.Textbox(label=\"Answer\"),\n",
    "        gr.Audio(label=\"Answer Audio\", type=\"filepath\")\n",
    "    ],\n",
    "    title=\"YouTube Transcript QA (Text & Voice Input)\",\n",
    "    description=\"Ask questions via text or audio and get answers based on YouTube transcripts, including spoken output.\",\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "# üü¢ Launch interface\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
